# Charla introductoria a la Inteligencia Artificial

Este repo tiene los recursos que usé para dar una charla introductoria sobre _Inteligencia Artificial_ en Junio de 2024 (at [fundar](https://www.fund.ar))

> [!IMPORTANT]
> Estas diapositivas están armadas como una suerte de _machete_ para poder explicar algunas cuestiones.
> Pueden estar incompletas o tener errores en su presentación. No pretenden reemplazar la bibliografía
> ni mejores fuentes de información.
> La charla fue muy resumida y no puede comprimir todos los temas en tan corto plazo de tiempo. Por ende
> es sólo un pantallazo de **cosas que existen**, no una explicación completa.


> [!NOTE]
> Para subsanar la brevedad de información, este repositorio tiene como función, aparte
> de contener el código fuente en LaTeX que usé para la presentación, ser una especie de
> _hub_ de información relacionada. :)


- [Serie de documentos de Fundar sobre Inteligencia Artificial](https://fund.ar/serie/inteligencia-artificial/)
- [Generador de caras](http://codeparade.net/faces/) - [(video)](https://www.youtube.com/watch?v=4VAkrUNLKSo)
- [Neural nachine translation by jointly learning to align and translate](https://arxiv.org/pdf/1409.0473) - Lo traje para mostrar las figuras _a, b, c, d_ de la sección 5.1, donde se visualmente se puede observar la atención del modelo a medida que traduce una oración de un lenguaje a otro.
- [Biografía de Arthur Samuel](https://history-computer.com/people/arthur-samuel-biography-history-and-inventions/)
- [Deceptive Learning - Apollo Research](https://www.apolloresearch.ai/research/our-research-on-strategic-deception-presented-at-the-uks-ai-safety-summit) - Extracto del _abstract_ del [paper](https://arxiv.org/pdf/2311.07590): _"[Muestran] una situación donde Modelos Grande de Lenguaje [LLMs], que fueron entrenados para ser serviciales, inofensivos y honestos, pueden mostrar comportamiento desalineado y estratégicamente engañar a sus usuarios sobre la verdad de sus actos sin ser instruídos para tal cosa. Concretamente, [despliegan] a GPT-4 como un agente en un ambiente realista simulado, donde asume el rol de un agente de trading de stocks. En [ese] ambiente [concluye involucrándose en el uso de información privilegiada, aunque se le haya indicado lo contrario]."_
- [Why Deceptive Learning matters for AGI](https://www.lesswrong.com/posts/oBFMbhQMt9HkmfF6d/why-deceptive-alignment-matters-for-agi-safety)
